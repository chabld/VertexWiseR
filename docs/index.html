<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="Provides functions to run statistical analyses on surface-based neuroimaging data, computing measures including cortical thickness and surface area of the whole-brain and of the hippocampi. It can make use of Freesurfer preprocessed datasets and Hippunfold hippocampal segmentation outputs for a given sample by restructuring the data values into a single file. The single file can then be used by the package for analyses independently from its base dataset and without need for its access.">
<title>Run Vertex-Wise Statistical Analyses in Whole-Brain and Hippocampal Surface Objects • VertexWiseR</title>
<script src="deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.11/clipboard.min.js" integrity="sha512-7O5pXpc0oCRrxk8RUfDYFgn0nO1t+jLuIOQdOMRp4APB7uZ4vSjspzp5y6YDtDs4VzUSTbWzBFZ/LKJhnyFOKw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="pkgdown.js"></script><meta property="og:title" content="Run Vertex-Wise Statistical Analyses in Whole-Brain and Hippocampal Surface Objects">
<meta property="og:description" content="Provides functions to run statistical analyses on surface-based neuroimaging data, computing measures including cortical thickness and surface area of the whole-brain and of the hippocampi. It can make use of Freesurfer preprocessed datasets and Hippunfold hippocampal segmentation outputs for a given sample by restructuring the data values into a single file. The single file can then be used by the package for analyses independently from its base dataset and without need for its access.">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light" data-bs-theme="light"><div class="container">
    
    <a class="navbar-brand me-2" href="index.html">VertexWiseR</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.0.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="reference/index.html">Reference</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/CogBrainHealthLab/VertexWiseR/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-home">
<div class="row">
  <main id="main" class="col-md-9"><p>Vertex-wise R functions for analyzing and visualizing cortical thickness</p>
<p><img src="reference/figures/Flowchart.jpg"><!-- --></p>
<p>================ Cognitive and Brain Health Laboratory 2024-04-30</p>
<div class="section level3">
<h3 id="setting-up-for-the-first-time">Setting up for the first time<a class="anchor" aria-label="anchor" href="#setting-up-for-the-first-time"></a>
</h3>
<p>VertexWiseR can be installed and loaded using the following code in R:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html" class="external-link">install.packages</a></span><span class="op">(</span><span class="st">"devtools"</span><span class="op">)</span></span>
<span><span class="fu">devtools</span><span class="fu">::</span><span class="fu"><a href="https://remotes.r-lib.org/reference/install_github.html" class="external-link">install_github</a></span><span class="op">(</span><span class="st">"CogBrainHealthLab/VertexWiseR"</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/CogBrainHealthLab/VertexWiseR" class="external-link">VertexWiseR</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co">##not yet available on CRAN at the moment</span></span>
<span>    <span class="co">#install.packages('VertexWiseR')</span></span></code></pre></div>
<p>VertexWiseR imports and makes use of the R package <code>reticulate</code>. <code>reticulate</code> is a package that allows R to borrow or translate python functions into R. Using reticulate, the package calls functions from the <code>brainstat</code> python module. Brainstat also comes with a number of fsaverage templates that need to be downloaded for use with VertexWiseR cortical analyses.</p>
<p>For reticulate to work properly with VertexWiseR, the latest version of <code>miniconda</code> needs to be installed with it — miniconda is a lightweight version of python, specifically for use within RStudio.</p>
<p>A function can be run to download and install all the system requirements (miniconda, brainstat, brainstat’s fsaverage templates) if they are not installed yet:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="reference/VWRfirstrun.html">VWRfirstrun</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<div class="section level4">
<h4 id="load-datasets">Load datasets<a class="anchor" aria-label="anchor" href="#load-datasets"></a>
</h4>
<p>For this example, we use Spreng and colleagues’s neurocognitive aging <a href="https://openneuro.org/datasets/ds003592/versions/1.0.13" class="external-link">openneuro dataset ds003592</a>:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">demodata</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html" class="external-link">read.csv</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/system.file.html" class="external-link">system.file</a></span><span class="op">(</span><span class="st">'demo_data/SPRENG_behdata.csv'</span>,</span>
<span>package <span class="op">=</span> <span class="st">'VertexWiseR'</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>The dataset T1 weighted images were preprocessed using the recon-all <a href="https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferWiki" class="external-link">Freesurfer</a> pipeline. This tutorial will not reiterate these steps and simply explain how, from a given Freesurfer subject directory, VertexWiseR extracts surface-based measures and synthesies the whole-sample data into a compact matrix object (.rds) for later analyses.</p>
<p>HIPvextract() gives the opportuntity to extract surface-based measures including ‘thickness’, ‘curv’, ‘sulc’, and ‘area’. Here, we are intersted in cortical thickness:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="reference/HIPvextract.html">HIPvextract</a></span><span class="op">(</span>sdirpath <span class="op">=</span> <span class="st">"MY_SUBJECTS_DIR/"</span>, filename <span class="op">=</span> <span class="st">"SPRENG_CTv.rds"</span>, measure <span class="op">=</span> <span class="st">"thickness"</span><span class="op">)</span> </span></code></pre></div>
<p>A CT matrix object extracted from this dataset is included in the VertexWiseR git repository and can be downloaded with the following code:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">SPRENG_CTv</span><span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/readRDS.html" class="external-link">readRDS</a></span><span class="op">(</span>file<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/connections.html" class="external-link">url</a></span><span class="op">(</span><span class="st">"https://github.com/CogBrainHealthLab/VertexWiseR/blob/main/inst/demo_data/SPRENG_CTv.rds?raw=TRUE"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="smoothing-the-surface-data">Smoothing the surface data<a class="anchor" aria-label="anchor" href="#smoothing-the-surface-data"></a>
</h4>
<p>VertexWiseR gives the option to smooth the surface data with a desiredfull width at half maximum (FWHM) value. It can also optionally directly be done as an option for vertex_analysis() which will be discussed below. Here, we smooth it before the analysis at 10 mm:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">SPRENG_CTv</span> <span class="op">=</span> <span class="fu"><a href="reference/smooth_surf.html">smooth_surf</a></span><span class="op">(</span><span class="va">SPRENG_CTv</span>, <span class="fl">10</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="preparing-the-model">Preparing the model<a class="anchor" aria-label="anchor" href="#preparing-the-model"></a>
</h4>
<p>The vertex-wise analysis model works as a multiple regression model where the Dependent Variable/outcome is the cortical thickness (CT) at each vertex, and you will decide which Independent Variables/predictors to enter into the model to predict the vertices’ CT. In this example, we shall use <code>age</code> and <code>sex</code> to predict CT. Among these IVs, we are mostly interested in age, sex being entered into the model to control for its confounding influence on CT. We thus select those two variables and save them into a new data.frame called <code>all_pred</code></p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">all_pred</span><span class="op">=</span><span class="va">demodata</span><span class="op">[</span>,<span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">7</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">all_pred</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb8"><pre class="sourceCode R"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="do">##   gender age</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="do">## 1      F  21</span></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a><span class="do">## 2      F  73</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a><span class="do">## 3      F  77</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="do">## 4      M  68</span></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a><span class="do">## 5      F  60</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a><span class="do">## 6      F  71</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="the-actual-analysis">The actual analysis<a class="anchor" aria-label="anchor" href="#the-actual-analysis"></a>
</h4>
<p>The next code chunk runs the analysis. There is an optional <code>p</code> parameter for the <code><a href="reference/vertex_analysis.html">vertex_analysis()</a></code> function to specify the p threshold; default p is set to 0.05. The atlas with which to label the significant clusters can also be set (1=Desikan (default), 2=Schaefer-100, 3=Schaefer-200, 4=Glasser-360, 5=Destrieux-148).</p>
<p>The second line displays the results.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">results</span><span class="op">=</span><span class="fu"><a href="reference/vertex_analysis.html">vertex_analysis</a></span><span class="op">(</span>model <span class="op">=</span> <span class="va">all_pred</span>, contrast <span class="op">=</span><span class="va">all_pred</span><span class="op">$</span><span class="va">age</span>, surf_data <span class="op">=</span> <span class="va">SPRENG_CTv</span>, atlas <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">results</span><span class="op">$</span><span class="va">cluster_level_results</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb10"><pre class="sourceCode R"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="do">## $`Positive contrast`</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="do">##   clusid nverts     P     X    Y   Z tstat          region</span></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="do">## 1      1    173 0.002 -22.8 11.5 -42  7.98 lh-temporalpole</span></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a><span class="do">## $`Negative contrast`</span></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a><span class="do">##   clusid nverts      P     X     Y    Z  tstat           region</span></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a><span class="do">## 1      1   8163 &lt;0.001  37.3 -31.6 16.3 -14.23 rh-supramarginal</span></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a><span class="do">## 2      2   8052 &lt;0.001 -34.0 -25.7 16.2 -15.29        lh-insula</span></span></code></pre></div>
<p>In the above results, the clusters that appear under the <code>Positive contrast</code> section are clusters of vertices which correlate positively with your <code>contrast</code> variable, vice-versa for the <code>Negative contrast</code>. In this instance, there are no significant clusters in the <code>Negative contrast</code>.</p>
<ul>
<li><p><code>nverts</code>: number of vertices in the cluster</p></li>
<li><p><code>P</code>: p-value of the cluster</p></li>
<li><p><code>X, Y and Z</code>: MNI coordinates of the vertex with the highest t-stat in the cluster.</p></li>
<li><p><code>tstat</code>: t statistic of the vertex with the highest t-stat in the cluster</p></li>
<li><p><code>region</code>: the region this highest t-stat vertex is located in. Here, it is determined/labelled using the <a href="https://surfer.nmr.mgh.harvard.edu/ftp/articles/desikan06-parcellation.pdf" class="external-link">Desikan atlas</a></p></li>
</ul>
</div>
<div class="section level4">
<h4 id="plotting">Plotting<a class="anchor" aria-label="anchor" href="#plotting"></a>
</h4>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="reference/plot_surf.html">plot_surf</a></span><span class="op">(</span>surf_data <span class="op">=</span> <span class="va">results</span><span class="op">$</span><span class="va">thresholded_tstat_map</span>, filename <span class="op">=</span> <span class="st">'sigcluster.jpg'</span>, surface <span class="op">=</span> <span class="st">'inflated'</span>, cmap <span class="op">=</span> <span class="st">'seismic'</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb12"><pre class="sourceCode R"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="do">## [1] "C:\\Users\\Admin\\My Drive\\workspace for analyses\\sigcluster.jpg"</span></span></code></pre></div>
<ul>
<li><p><code>surf_data</code>: A matrix object containing the surface data (N rows for participants and M columns for vertices). It can be the output from SURFvextract() as well as masks outputted by analyses functions.</p></li>
<li><p><code>filename</code>: filename of the output image</p></li>
<li>
<p><code>cmap</code> (optional) : A string object containing the colormap for the plot. Options are listed in the .</p>
<p>Default cmap is set to <code>"Reds"</code> for positive values, <code>"Blues"</code> for negative values and <code>"RdBu"</code> when both positive and negative values exist.</p>
</li>
<li><p><code>title</code> (optional) : text label displayed on the left</p></li>
<li><p><code>surface</code> (optional) : type of cortical surface background rendered. Possible options include <code>"white"</code>, <code>"smoothwm"</code>,<code>"pial"</code> and <code>"inflated"</code> (default)</p></li>
</ul>
<p><img src="reference/figures/sigcluster.jpg"></p>
</div>
<div class="section level4">
<h4 id="extracting-the-ct-values-for-each-subject">Extracting the CT values for each subject<a class="anchor" aria-label="anchor" href="#extracting-the-ct-values-for-each-subject"></a>
</h4>
<p>If you want to carry out some follow-up analyses (e.g., mediation), you might want to extract, for each subject in the dataset, the mean CT in the significant clusters colored in red (positive clusters). You can simply do a matrix multiplication (operator for matrix multiplication :<code>%*%</code>) between the CT data <code>SPRENG_CTv</code> and the positive mask <code>results$pos_mask</code> . A mask in the context of brain images refers to a vector of 1s and 0s. In this case, the vertices which are within the significant clusters are coded as 1s, vertices outside these significant clusters are coded as 0s. <code>sum(results$pos_mask)</code> gives you the sum of all the 1s, which essentially is the number of significant vertices. Thus, the <code>SPRENG_CTv %*% results$pos_mask</code> is divided by <code>sum(results$pos_mask)</code> to obtain an average CT value. Here, this average CT is saved into a new variable <code>sig_avCT</code> within the <code>demodata</code> dataframe.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">demodata</span><span class="op">$</span><span class="va">sig_avCT</span><span class="op">=</span><span class="va">SPRENG_CTv</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">results</span><span class="op">$</span><span class="va">pos_mask</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">results</span><span class="op">$</span><span class="va">pos_mask</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">demodata</span><span class="op">$</span><span class="va">sig_avCT</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb14"><pre class="sourceCode R"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="do">##          [,1]</span></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a><span class="do">## [1,] 2.728489</span></span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a><span class="do">## [2,] 2.974559</span></span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a><span class="do">## [3,] 2.573237</span></span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a><span class="do">## [4,] 2.886865</span></span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a><span class="do">## [5,] 3.169464</span></span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a><span class="do">## [6,] 3.007699</span></span></code></pre></div>
<p>as a sanity check, these mean CT values should correlate with <code>age</code></p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/cor.test.html" class="external-link">cor.test</a></span><span class="op">(</span><span class="va">demodata</span><span class="op">$</span><span class="va">sig_avCT</span>,<span class="va">demodata</span><span class="op">$</span><span class="va">age</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb16"><pre class="sourceCode R"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a><span class="do">##  Pearson's product-moment correlation</span></span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a><span class="do">## data:  demodata$sig_avCT and demodata$age</span></span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a><span class="do">## t = 5.5789, df = 299, p-value = 5.423e-08</span></span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a><span class="do">## alternative hypothesis: true correlation is not equal to 0</span></span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a><span class="do">## 95 percent confidence interval:</span></span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a><span class="do">##  0.2009735 0.4060082</span></span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a><span class="do">## sample estimates:</span></span>
<span id="cb16-10"><a href="#cb16-10" tabindex="-1"></a><span class="do">##       cor </span></span>
<span id="cb16-11"><a href="#cb16-11" tabindex="-1"></a><span class="do">## 0.3070495 </span></span></code></pre></div>
</div>
</div>
<div class="section level1">
<div class="page-header"><h1 id="image-decoding">Image decoding<a class="anchor" aria-label="anchor" href="#image-decoding"></a>
</h1></div>
<div class="section level3">
<h3 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h3>
<p>After running the whole-brain vertex-wise analyses, you may be able to identify regions in the brain in which cortical thickness (CT) values are significantly different between groups or these CT values predict a certain IV significantly. How do we make sense of these regions? We can plot out the results using the <code><a href="reference/plot_surf.html">plot_surf()</a></code> function, but still, it may be difficult to interpret the results in terms of the functional relevance of the regions identified. So here’s a tool you can use to facilitate such interpretations.</p>
<p>What this tool does is to correlate your input image (cortical surface maps obtained from an earlier vertex-wise analysis) with images from a large database of task-based fMRI and voxel-based morphometric studies. Each of these images in the database is tagged with a few keywords, describing the task and/or sample characteristics. The correlations that are carried out essentially measure how similar your input image is to each of the images in the database. Higher correlations would mean that your input image looks very similar to a certain image in the database, thus the keywords associated with that image in the database would be highly relevant to your input image.</p>
<p>In this worked example, we will first run a whole-brain vertex-wise analysis to compare the cortical thickness between males and females in the young adult population of the SPRENG dataset. The thresholded cortical surface maps obtained from this analysis will then be fed into an image-decoding procedure to identify keywords that are relevant to our results</p>
</div>
<div class="section level3">
<h3 id="source-custom-made-r-functions-from-github">Source custom-made R functions from Github<a class="anchor" aria-label="anchor" href="#source-custom-made-r-functions-from-github"></a>
</h3>
<p>The <a href="https://nimare.readthedocs.io/en/stable/index.html" class="external-link">NiMARE</a> python module is needed in order for the imaging decoding to work. It is similarly imported by VertexWiseR via reticulate in the decode_surf_data() function.</p>
</div>
<div class="section level3">
<h3 id="load-and-prepare-data">Load and prepare data<a class="anchor" aria-label="anchor" href="#load-and-prepare-data"></a>
</h3>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#filter out old participants</span></span>
<span><span class="va">dat_beh</span><span class="op">=</span><span class="va">demodata</span><span class="op">[</span><span class="va">demodata</span><span class="op">$</span><span class="va">agegroup</span><span class="op">==</span><span class="st">"Y"</span>,<span class="op">]</span></span>
<span><span class="va">dat_CT</span><span class="op">=</span><span class="va">SPRENG_CTv</span><span class="op">[</span><span class="va">demodata</span><span class="op">$</span><span class="va">agegroup</span><span class="op">==</span><span class="st">"Y"</span>,<span class="op">]</span></span>
<span></span>
<span><span class="co">##recoding categorical variables into numeric form for the vertex-wise analysis</span></span>
<span><span class="va">dat_beh</span><span class="op">$</span><span class="va">sex_recode</span><span class="op">=</span><span class="fl">0</span></span>
<span><span class="va">dat_beh</span><span class="op">$</span><span class="va">sex_recode</span><span class="op">[</span><span class="va">dat_beh</span><span class="op">$</span><span class="va">gender</span><span class="op">==</span><span class="st">"F"</span><span class="op">]</span><span class="op">=</span><span class="fl">1</span></span>
<span><span class="va">all_pred</span><span class="op">=</span><span class="va">dat_beh</span><span class="op">[</span>,<span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">3</span>,<span class="fl">7</span>,<span class="fl">72</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">all_pred</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb18"><pre class="sourceCode R"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="do">##    site age sex_recode</span></span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a><span class="do">## 1     1  21          1</span></span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a><span class="do">## 15    1  32          0</span></span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a><span class="do">## 16    1  20          0</span></span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a><span class="do">## 17    1  21          0</span></span>
<span id="cb18-6"><a href="#cb18-6" tabindex="-1"></a><span class="do">## 18    1  24          0</span></span>
<span id="cb18-7"><a href="#cb18-7" tabindex="-1"></a><span class="do">## 19    1  20          0</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="vertex-wise-analysis">Vertex-wise analysis<a class="anchor" aria-label="anchor" href="#vertex-wise-analysis"></a>
</h3>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">results</span><span class="op">=</span><span class="fu"><a href="reference/vertex_analysis.html">vertex_analysis</a></span><span class="op">(</span>model <span class="op">=</span> <span class="va">all_pred</span>, contrast <span class="op">=</span><span class="va">all_pred</span><span class="op">$</span><span class="va">sex_recode</span>, surf_data <span class="op">=</span> <span class="va">dat_CT</span><span class="op">)</span></span>
<span><span class="va">results</span><span class="op">$</span><span class="va">cluster_level_results</span></span></code></pre></div>
<div class="sourceCode" id="cb20"><pre class="sourceCode R"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a><span class="do">## $`Positive contrast`</span></span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a><span class="do">## [1] "No significant clusters"</span></span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb20-4"><a href="#cb20-4" tabindex="-1"></a><span class="do">## $`Negative contrast`</span></span>
<span id="cb20-5"><a href="#cb20-5" tabindex="-1"></a><span class="do">##   clusid nverts      P     X     Y    Z tstat                  region</span></span>
<span id="cb20-6"><a href="#cb20-6" tabindex="-1"></a><span class="do">## 1      1    300 &lt;0.001 -39.2 -12.6 16.2 -4.59               lh-insula</span></span>
<span id="cb20-7"><a href="#cb20-7" tabindex="-1"></a><span class="do">## 2      2    157  0.007  40.0 -15.9 -5.7 -4.22               rh-insula</span></span>
<span id="cb20-8"><a href="#cb20-8" tabindex="-1"></a><span class="do">## 3      3    103  0.009 -19.3  57.2 -6.2 -3.19 lh-rostralmiddlefrontal</span></span></code></pre></div>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="reference/plot_surf.html">plot_surf</a></span><span class="op">(</span>surf_data <span class="op">=</span> <span class="va">results</span><span class="op">$</span><span class="va">thresholded_tstat_map</span>,filename <span class="op">=</span> <span class="st">"sexdiff.jpg"</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb22"><pre class="sourceCode R"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a><span class="do">## [1] "C:\\Users\\Admin\\My Drive\\workspace for analyses\\sexdiff.jpg"</span></span></code></pre></div>
<p><img src="reference/figures/sexdiff.jpg"></p>
<p>According to these results, since the female sex is coded as 1 and males as 0, the regions colored in cyan are thicker in males</p>
</div>
<div class="section level3">
<h3 id="image-decoding-1">Image decoding<a class="anchor" aria-label="anchor" href="#image-decoding-1"></a>
</h3>
<p>Now, let’s enter the <code>thresholded_tstat_map</code> into the <code>decode_img()</code> function. The previous results only contained negative clusters. But in case of bidirectionality, the function requires to choose one direction with the contrast option. In this instance, we simply decode the negative clusters, by setting <code>contrast="negative"</code>.</p>
<p>If you are running this for the first time, a ~8 MB file <code>neurosynth_dataset.pkl.gz</code> will be downloaded to your current directory. This file will contain the images from the <a href="https://neurosynth.org/" class="external-link">Neurosynth</a> database that will be correlated with your input image.</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">keywords</span><span class="op">=</span><span class="fu"><a href="reference/decode_surf_data.html">decode_surf_data</a></span><span class="op">(</span>surf_data<span class="op">=</span><span class="va">results</span><span class="op">$</span><span class="va">thresholded_tstat_map</span>, contrast <span class="op">=</span> <span class="st">"negative"</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb24"><pre class="sourceCode R"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a><span class="do">## Correlating input image with images in the neurosynth database. This may take a while</span></span></code></pre></div>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">keywords</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span>,<span class="op">]</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb26"><pre class="sourceCode R"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" tabindex="-1"></a><span class="do">##    keyword     r</span></span>
<span id="cb26-2"><a href="#cb26-2" tabindex="-1"></a><span class="do">## 524      pain 0.109</span></span>
<span id="cb26-3"><a href="#cb26-3" tabindex="-1"></a><span class="do">## 57   auditory 0.088</span></span>
<span id="cb26-4"><a href="#cb26-4" tabindex="-1"></a><span class="do">## 718    speech 0.087</span></span>
<span id="cb26-5"><a href="#cb26-5" tabindex="-1"></a><span class="do">## 392 listening 0.084</span></span>
<span id="cb26-6"><a href="#cb26-6" tabindex="-1"></a><span class="do">## 763  temporal 0.077</span></span>
<span id="cb26-7"><a href="#cb26-7" tabindex="-1"></a><span class="do">## 525   painful 0.076</span></span>
<span id="cb26-8"><a href="#cb26-8" tabindex="-1"></a><span class="do">## 460   musical 0.064</span></span>
<span id="cb26-9"><a href="#cb26-9" tabindex="-1"></a><span class="do">## 459     music 0.062</span></span>
<span id="cb26-10"><a href="#cb26-10" tabindex="-1"></a><span class="do">## 707    sounds 0.062</span></span>
<span id="cb26-11"><a href="#cb26-11" tabindex="-1"></a><span class="do">## 661 secondary 0.057</span></span></code></pre></div>
<p>The above procedure will display the top 10 keywords from images in the database that are the most correlated with your input image. According to these results, you can see that the negative clusters (which are thicker in males) are typically found to be associated with pain and auditory processing. If you simply run <code>keyword</code> without specifying the index within the square brackets <code>[1:10,]</code>. All 847 keywords will be displayed.</p>
<p>In your presentation slides or results section of your paper, you might want to illustrate these keywords using a wordcloud. You can set the size of the keyword to vary according to its r value</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#install.packages("wordcloud","paletteer")</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="http://blog.fellstat.com/?cat=11" class="external-link">wordcloud</a></span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb28"><pre class="sourceCode R"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" tabindex="-1"></a><span class="do">## Loading required package: RColorBrewer</span></span></code></pre></div>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/EmilHvitfeldt/paletteer" class="external-link">paletteer</a></span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/wordcloud/man/wordcloud.html" class="external-link">wordcloud</a></span><span class="op">(</span>words <span class="op">=</span> <span class="va">keywords</span><span class="op">$</span><span class="va">keyword</span>, <span class="co">##keyword input</span></span>
<span>          freq <span class="op">=</span> <span class="va">keywords</span><span class="op">$</span><span class="va">r</span>, <span class="co">##setting the size of the keyword to vary with its r value</span></span>
<span>          min.freq <span class="op">=</span> <span class="fl">0.05</span>, <span class="co">##minimum r value in order for the keyword to be displayed</span></span>
<span>          colors<span class="op">=</span><span class="fu"><a href="https://rdrr.io/pkg/paletteer/man/paletteer_c.html" class="external-link">paletteer_c</a></span><span class="op">(</span><span class="st">"grDevices::Temps"</span>, <span class="fl">10</span><span class="op">)</span> <span class="co">##color scheme</span></span>
<span>          ,scale<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span> </span>
<span>          <span class="op">)</span> </span>
<span>          <span class="fu"><a href="https://rdrr.io/r/graphics/par.html" class="external-link">par</a></span><span class="op">(</span>mar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="reference/figures/wordcloud.jpg"><!-- --></p>
<p>These keywords may not be very accurate but they should give a rough idea for interpreting your results. Take note that these keywords are specific to the negative clusters.</p>
</div>
</div>

  </main><aside class="col-md-3"><div class="links">
<h2 data-toc-skip>Links</h2>
<ul class="list-unstyled">
<li><a href="https://github.com/CogBrainHealthLab/VertexWiseR/" class="external-link">Browse source code</a></li>
</ul>
</div>

<div class="license">
<h2 data-toc-skip>License</h2>
<ul class="list-unstyled">
<li>
<a href="https://www.r-project.org/Licenses/GPL-3" class="external-link">GPL-3</a> + file <a href="LICENSE-text.html">LICENSE</a>
</li>
</ul>
</div>


<div class="citation">
<h2 data-toc-skip>Citation</h2>
<ul class="list-unstyled">
<li><a href="authors.html#citation">Citing VertexWiseR</a></li>
</ul>
</div>

<div class="developers">
<h2 data-toc-skip>Developers</h2>
<ul class="list-unstyled">
<li>Junhong Yu <br><small class="roles"> Author, maintainer </small> <a href="https://orcid.org/0000-0002-2563-9658" target="orcid.widget" aria-label="ORCID" class="external-link"><span class="fab fa-orcid orcid" aria-hidden="true"></span></a> </li>
<li>Charly Billaud <br><small class="roles"> Author </small> <a href="https://orcid.org/0009-0001-3466-9963" target="orcid.widget" aria-label="ORCID" class="external-link"><span class="fab fa-orcid orcid" aria-hidden="true"></span></a> </li>
</ul>
</div>



  </aside>
</div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Junhong Yu, Charly Billaud.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.9.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
